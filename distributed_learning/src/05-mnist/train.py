import tensorflow as tf

layers = tf.contrib.layers
learn = tf.contrib.learn

tf.logging.set_verbosity(tf.logging.INFO)


def neural_network(feature, target, mode):
    # Convert the target to a one-hot tensor of shape (batch_size, 10) and
    # with a on-value of 1 for each one-hot vector of length 10.
    target = tf.one_hot(
        tf.cast(target, tf.int32), 10, 1, 0
    )

    # Reshape feature to 4d tensor with 2nd and 3rd dimensions being
    # image width and height final dimension being the number of color channels.
    feature = tf.reshape(feature, [-1, 28, 28, 1])

    # First conv layer will compute 32 features for each 5x5 patch
    with tf.variable_scope("conv_layer1"):
        h_conv1 = layers.conv2d(
            feature,
            32,
            kernel_size=[5, 5],
            activation_fn=tf.nn.relu,
        )
        h_pool1 = tf.nn.max_pool(
            h_conv1,
            ksize=[1, 2, 2, 1],
            strides=[1, 2, 2, 1],
            padding="SAME",
        )

    # Second conv layer will compute 64 features for each 5x5 patch.
    with tf.variable_scope("conv_layer2"):
        h_conv2 = layers.conv2d(
            h_pool1,
            64,
            kernel_size=[5, 5],
            activation_fn=tf.nn.relu,
        )
        h_pool2 = tf.nn.max_pool(
            h_conv2,
            ksize=[1, 2, 2, 1],
            strides=[1, 2, 2, 1],
            padding="SAME",
        )
        # reshape tensor into a batch of vectors
        h_pool2_flat = tf.reshape(
            h_pool2, [-1, 7 * 7 * 64]
        )

    # Densely connected layer with 1024 neurons.
    h_fc1 = layers.dropout(
        layers.fully_connected(
            h_pool2_flat,
            1024,
            activation_fn=tf.nn.relu,
        ),
        keep_prob=0.5,
        is_training=mode
        == tf.contrib.learn.ModeKeys.TRAIN,
    )

    # Compute logits (1 per class) and compute loss.
    logits = layers.fully_connected(
        h_fc1, 10, activation_fn=None
    )
    loss = tf.losses.softmax_cross_entropy(
        target, logits
    )

    return tf.argmax(logits, 1), loss


def main(_):
    mnist = learn.datasets.mnist.read_data_sets(
        "/src/datasets/"
    )

    with tf.name_scope("input"):
        image = tf.placeholder(
            tf.float32, [None, 784], name="image"
        )
        label = tf.placeholder(
            tf.float32, [None], name="label"
        )

    predict, loss = neural_network(
        image, label, tf.contrib.learn.ModeKeys.TRAIN
    )

    opt = tf.train.RMSPropOptimizer(0.01)

    global_step = tf.train.get_or_create_global_step()
    train_op = opt.minimize(
        loss, global_step=global_step
    )

    hooks = [
        tf.train.StopAtStepHook(last_step=100),
        tf.train.LoggingTensorHook(
            tensors={
                "step": global_step,
                "loss": loss,
            },
            every_n_iter=10,
        ),
    ]

    with tf.train.SingularMonitoredSession(
        hooks=hooks
    ) as sess:
        while not sess.should_stop():
            image_, label_ = mnist.train.next_batch(
                100
            )
            sess.run(
                train_op,
                feed_dict={
                    image: image_,
                    label: label_,
                },
            )


if __name__ == "__main__":
    tf.app.run()
